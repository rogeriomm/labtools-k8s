# https://artifacthub.io/packages/helm/airflow-helm/airflow/8.4.0
# https://github.com/airflow-helm/charts/blob/main/charts/airflow/values.yaml

airflow:
  image:
    repository: registry.minikube/airflow-2.7.3-10
    tag: master

  clusterDomain: cluster2.xpt

  config:
    AIRFLOW__WEBSERVER__BASE_URL: "https://airflow.worldl.xpt/airflow"
    AIRFLOW__CELERY__FLOWER_URL_PREFIX: "/flower"
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"

  ## a list of users to create
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/security/airflow-users.md
  users:
    - username: admin
      password: admin
      role: Admin
      email: email@gmail.com
      firstName: admin
      lastName: admin

  ## a list airflow variables to create
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/dags/airflow-variables.md
  variables:
    - key: "environment"
      value: "dev"

  ## extra pip packages to install in airflow Pods
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/configuration/extra-python-packages.md
  ## [WARNING] this feature is not recommended for production use, see docs
  extraPipPackages: []

  ## extra environment variables for the airflow Pods
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/kubernetes/mount-environment-variables.md
  extraEnv:
    - name: AIRFLOW__CORE__TEST_CONNECTION
      value: Enabled

  ## extra VolumeMounts for the airflow Pods
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/kubernetes/mount-persistent-volumes.md
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/kubernetes/mount-files.md
  extraVolumeMounts: []

  ## extra Volumes for the airflow Pods
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/kubernetes/mount-persistent-volumes.md
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/kubernetes/mount-files.md
  extraVolumes:
    - name: worker-tmp
      persistentVolumeClaim:
        claimName: worker-tmp

  kubernetesPodTemplate:
    extraVolumeMounts:
      - name: data-lab-volume
        mountPath: /Volumes/data/git
        readOnly: false

    extraVolumes:
      - name: data-lab-volume
        persistentVolumeClaim:
          claimName: nfs-common

  connections:
      - id: postgres_datahub
        type: postgres
        description: "Postgres datahub db"
        host: postgres-postgresql.postgres.svc.cluster2.xpt
        port: 5432
        schema: datahub
        login: ${POSTGRES_USERNAME}
        password: ${POSTGRES_PASSWORD}

      - id: postgres_hive_metastore
        type: postgres
        description: "Postgres Hive metastore db"
        host: postgres-postgresql.postgres.svc.cluster2.xpt
        port: 5432
        schema: metastore_db
        login: ${POSTGRES_USERNAME}
        password: ${POSTGRES_PASSWORD}

      - id: mongodb
        type: mongo
        description: "MongoDB"
        host: mongodb-1-svc.mongodb.svc.cluster2.xpt
        port: 27017
        schema: my_database
        login: ${MONGODB_USERNAME}
        password: ${MONGODB_PASSWORD}

  connectionsTemplates:
    POSTGRES_USERNAME:
      kind: secret
      name: postgres-user-airflow
      key: user

    POSTGRES_PASSWORD:
      kind: secret
      name: postgres-user-airflow
      key: password

    MONGODB_USERNAME:
      kind: secret
      name: mongodb-user-airflow
      key: user

    MONGODB_PASSWORD:
      kind: secret
      name: mongodb-user-airflow
      key: password

###################################
## COMPONENT | Airflow Workers
###################################
workers:
  ## if the airflow workers StatefulSet should be deployed
  ##
  enabled: true

  ## the number of worker Pods to run
  ## - if you set this >1 we recommend defining a `workers.podDisruptionBudget`
  ## - this is the minimum when `workers.autoscaling.enabled` is true
  ##
  replicas: 1

  ## resource requests/limits for the worker Pod
  ## - spec for ResourceRequirements:
  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core
  ##
  resources: {}

  ## the nodeSelector configs for the worker Pods
  ## - docs for nodeSelector:
  ##   https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
  ##
  nodeSelector: {}

  ## the affinity configs for the worker Pods
  ## - spec for Affinity:
  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#affinity-v1-core
  ##
  affinity: {}

  ## the toleration configs for the worker Pods
  ## - spec for Toleration:
  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#toleration-v1-core
  ##
  tolerations: []

  ## the security context for the worker Pods
  ## - spec for PodSecurityContext:
  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core
  ##
  securityContext: {}

  ## labels for the worker StatefulSet
  ##
  labels: {}

  ## Pod labels for the worker StatefulSet
  ##
  podLabels: {}

  ## annotations for the worker StatefulSet
  ##
  annotations: {}

  ## Pod annotations for the worker StatefulSet
  ##
  podAnnotations: {}

  ## if we add the annotation: "cluster-autoscaler.kubernetes.io/safe-to-evict" = "true"
  ##
  safeToEvict: true

  ## configs for the PodDisruptionBudget of the worker StatefulSet
  ##
  podDisruptionBudget:
    ## if a PodDisruptionBudget resource is created for the worker StatefulSet
    ##
    enabled: false

    ## the `apiVersion` to use for PodDisruptionBudget resources
    ## - for Kubernetes 1.21 and later: "policy/v1"
    ## - for Kubernetes 1.20 and before: "policy/v1beta1"
    ##
    apiVersion: policy/v1

    ## the maximum unavailable pods/percentage for the worker StatefulSet
    ##
    maxUnavailable: ""

    ## the minimum available pods/percentage for the worker StatefulSet
    ##
    minAvailable: ""

  ## configs for the HorizontalPodAutoscaler of the worker Pods
  ## - [WARNING] if using git-sync, ensure `dags.gitSync.resources` is set
  ## - [WARNING] if using worker log-cleanup, ensure `workers.logCleanup.resources` is set
  ##
  ## ____ EXAMPLE _______________
  ##   autoscaling:
  ##     enabled: true
  ##     maxReplicas: 16
  ##     metrics:
  ##     - type: Resource
  ##       resource:
  ##         name: memory
  ##         target:
  ##           type: Utilization
  ##           averageUtilization: 80
  ##
  autoscaling:
    enabled: false
    maxReplicas: 2
    metrics: []

    ## the `apiVersion` to use for HorizontalPodAutoscaler resources
    ## - for Kubernetes 1.23 and later: "autoscaling/v2"
    ## - for Kubernetes 1.22 and before: "autoscaling/v2beta2"
    ##
    apiVersion: autoscaling/v2

  ## configs for the celery worker Pods
  ##
  celery:
    ## if celery worker Pods are gracefully terminated
    ## - consider defining a `workers.podDisruptionBudget` to prevent there not being
    ##   enough available workers during graceful termination waiting periods
    ##
    ## graceful termination process:
    ##  1. prevent worker accepting new tasks
    ##  2. wait AT MOST `workers.celery.gracefullTerminationPeriod` for tasks to finish
    ##  3. send SIGTERM to worker
    ##  4. wait AT MOST `workers.terminationPeriod` for kill to finish
    ##  5. send SIGKILL to worker
    ##
    gracefullTermination: false

    ## how many seconds to wait for tasks to finish before SIGTERM of the celery worker
    ##
    gracefullTerminationPeriod: 600

  ## how many seconds to wait after SIGTERM before SIGKILL of the celery worker
  ## - [WARNING] tasks that are still running during SIGKILL will be orphaned, this is important
  ##   to understand with KubernetesPodOperator(), as Pods may continue running
  ##
  terminationPeriod: 60

  ## configs for the log-cleanup sidecar of the worker Pods
  ## - helps prevent excessive log buildup by regularly deleting old files
  ##
  logCleanup:
    ## if the log-cleanup sidecar is enabled
    ## - [WARNING] must be disabled if `logs.persistence.enabled` is `true`
    ##
    enabled: false

    ## resource requests/limits for the log-cleanup container
    ## - spec of ResourceRequirements:
    ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core
    ##
    resources: {}

    ## the number of minutes to retain log files (by last-modified time)
    ##
    retentionMinutes: 21600

    ## the number of seconds between each check for files to delete
    ##
    intervalSeconds: 900

  ## configs for the worker Pods' liveness probe
  ##
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 60
    failureThreshold: 5

  ## extra pip packages to install in the worker Pod
  ##
  ## ____ EXAMPLE _______________
  ##   extraPipPackages:
  ##     - "SomeProject==1.0.0"
  ##
  extraPipPackages: []

  ## extra VolumeMounts for the worker Pods
  ## - spec for VolumeMount:
  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volumemount-v1-core
  ##
  extraVolumeMounts:
    - name: data-lab-volume
      mountPath: /Volumes/data/git
      readOnly: false

  ## extra Volumes for the worker Pods
  ## - spec for Volume:
  ##   https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#volume-v1-core
  ##
  extraVolumes:
    - name: data-lab-volume
      persistentVolumeClaim:
        claimName: nfs-common

###################################
## COMPONENT | Airflow Scheduler
###################################
scheduler:
  ## the number of scheduler Pods to run
  replicas: 1

  ## resource requests/limits for the scheduler Pods
  ## [SPEC] https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#resourcerequirements-v1-core
  resources: {}

  ## configs for the log-cleanup sidecar of the scheduler
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/monitoring/log-cleanup.md
  logCleanup:
    enabled: false
    retentionMinutes: 21600

  ## configs for the scheduler Pods' liveness probe
  ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/monitoring/scheduler-liveness-probe.md
  livenessProbe:
    enabled: true

    ## configs for an additional check that ensures tasks are being created by the scheduler
    ## [FAQ] https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/monitoring/scheduler-liveness-probe.md
    taskCreationCheck:
      enabled: false
      thresholdSeconds: 300
      schedulerAgeBeforeCheck: 180

# https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/database/external-database.md
postgresql:
  enabled: false

externalDatabase:
  type: postgres

  host: postgres-postgresql.postgres.svc.cluster2.xpt
  port: 5432

  ## the schema which will contain the airflow tables
  database: airflow

  ## Kubernetes secret in your airflow namespace
  userSecret: "postgres-user-airflow"
  userSecretKey: "user"

  ## Kubernetes secret in your airflow namespace
  passwordSecret: "postgres-user-airflow"
  passwordSecretKey: "password"

  ## use this for any extra connection-string settings, e.g. ?sslmode=disable
  properties: ""

# https://github.com/airflow-helm/charts/blob/main/charts/airflow/docs/faq/kubernetes/ingress.md
ingress:
  enabled: true
  ## WARNING: set as "networking.k8s.io/v1beta1" for Kubernetes 1.18 and earlier
  apiVersion: networking.k8s.io/v1

  ## airflow webserver ingress configs
  web:
    annotations: {}
    host: "airflow.worldl.xpt"
    path: "/airflow"
    ## WARNING: requires Kubernetes 1.18 or later, use "kubernetes.io/ingress.class" annotation for older versions
    ingressClassName: "nginx"

  ## flower ingress configs
  flower:
    annotations: {}
    host: "airflow.worldl.xpt"
    path: "/flower"
    ## WARNING: requires Kubernetes 1.18 or later, use "kubernetes.io/ingress.class" annotation for older versions
    ingressClassName: "nginx"

###################################
## CONFIG | Airflow Logs
###################################
logs:
  ## the airflow logs folder
  ##
  path: /opt/airflow/logs

  ## configs for the logs PVC
  ##
  persistence:
    ## if a persistent volume is mounted at `logs.path`
    ##
    enabled: true

    ## the name of an existing PVC to use
    ##
    existingClaim: "worker-tmp"

    ## sub-path under `logs.persistence.existingClaim` to use
    ##
    subPath: ""

    ## the name of the StorageClass used by the PVC
    ## - if set to "", then `PersistentVolumeClaim/spec.storageClassName` is omitted
    ## - if set to "-", then `PersistentVolumeClaim/spec.storageClassName` is set to ""
    ##
    storageClass: ""

    ## the access mode of the PVC
    ## - [WARNING] must be "ReadWriteMany" or airflow pods will fail to start
    ##
    accessMode: ReadWriteMany

    ## the size of PVC to request
    ##
    size: 1Gi

###################################
## CONFIG | Airflow DAGs
###################################
dags:
  ## NOTE: this is the default value
  path: /opt/airflow/dags

  persistence:
    enabled: true

    ## NOTE: this is name of your existing volume
    existingClaim: airflow-dags

    ## sub-path under `dags.persistence.existingClaim` to use
    subPath: "labtools-k8s/data/airflow/dags"

    ## NOTE: as multiple Pods read the DAGs concurrently this MUST be ReadOnlyMany or ReadWriteMany
    accessMode: ReadOnlyMany
