apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: debezium-connector-sqlserver
  labels:
    strimzi.io/cluster: my-connect
spec:
  class: io.debezium.connector.sqlserver.SqlServerConnector
  tasksMax: 1
  config:
    converter.type: avro
    key.converter: "io.confluent.connect.avro.AvroConverter"
    key.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    value.converter: "io.confluent.connect.avro.AvroConverter"
    value.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    database.hostname: mssqlserver-2022.sqlserver.svc
    database.port: 1433
    database.dbname: test
    database.user: sa
    database.password: ZAyPsMK9RM99SfYfaz6W
    table.whitelist: "dbo.subscription,dbo.company,dbo.credit_card"
    database.server.name: mssqlserver-2022.sqlserver.svc
    #message.key.columns: ""
    database.history.kafka.bootstrap.servers: main-kafka-bootstrap:9092
    database.history.kafka.topic: sqlserver-cdc-tables
    decimal.handling.mode: double
    tombstones.on.delete: true
    poll.interval.ms: 20000
    max.batch.size: 600
    max.queue.size: 1200
    query.fetch.size: 1000
    snapshot.fetch.size: 600

    # Debezium Avro serialization configurations

    transforms: "unwrap"
    transforms.unwrap.type: "io.debezium.transforms.ExtractNewRecordState"
    transforms.unwrap.add.headers: "db"
    transforms.unwrap.add.fields: "op,table,source.ts_ms"
    transforms.unwrap.drop.tombstones: "false"
    transforms.unwrap.delete.handling.mode: "rewrite"
